{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Introduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "goal: to analysis flight booking data form database to get the past booking status of previous day, previous 7, 15 and 30 day\n",
    "\n",
    "process flow:\n",
    "1. get input from blade to python script\n",
    "2. extract data from database\n",
    "3. transform data\n",
    "4. filter data\n",
    "5. process data\n",
    "6. send data as json to depict using charts\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Process input from blade to python script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "# Debug: Print arguments to verify\n",
    "print(\"Arguments passed to script:\", sys.argv)\n",
    "\n",
    "# Ensure you have the deviation argument\n",
    "if len(sys.argv) != 4:\n",
    "    print(\"Usage: python script.py <deviation>\")\n",
    "    sys.exit(1)\n",
    "\n",
    "try:\n",
    "    deviation   = float(sys.argv[1])\n",
    "    startDate   = sys.argv[2]\n",
    "    endDate     = sys.argv[3]\n",
    "except ValueError:\n",
    "    print(\"The deviation argument must be a float.\")\n",
    "    sys.exit(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EXtract data from database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"---------START: Reading Data---------\")\n",
    " \n",
    "import pymysql\n",
    " \n",
    "mydb = pymysql.connect(\n",
    "    host     = \"host_name\",\n",
    "    user     = \"user_name\",\n",
    "    database = \"db_name\",\n",
    "    password = \"password\")\n",
    "\n",
    "column_header = ['route','flight_no','flight_date', 'total_seat','total_booked','plf','generated_at']\n",
    "\n",
    "mycursor = mydb.cursor()\n",
    "mycursor.execute('select route,flight_no,flight_date, total_seat, total_booked,plf,generated_at from table_name')\n",
    "\n",
    "df = pd.DataFrame(mycursor.fetchall())\n",
    "df.columns = column_header\n",
    "\n",
    "# print(\"---------END: Reading Data---------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# print(\"---------START: Transforming Data---------\")\n",
    "\n",
    "# Convert the columns to desired object.\n",
    "df['flight_date']   = pd.to_datetime(df['flight_date'])\n",
    "df['generated_at']  = pd.to_datetime(df['generated_at'])\n",
    "df['total_seat']    = df['total_seat'].astype(int)\n",
    "df['total_booked']  = df['total_booked'].astype(int)\n",
    "df['plf']           = df['plf'].apply(lambda x: round(float(x), 2))\n",
    "\n",
    "# print(\"---------END: Transforming Data---------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "today_date      = pd.to_datetime('today')\n",
    "start_date      = pd.to_datetime(startDate)\n",
    "end_date        = pd.to_datetime(endDate)\n",
    "\n",
    "past_flights    = df[(df['flight_date'] <= end_date) & (df['flight_date'] >= start_date)]\n",
    "past_flights_grouped = past_flights.loc[past_flights.groupby([ 'flight_no', 'flight_date','route'])['generated_at'].idxmax()]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"---------START: Analyzing Data---------\")\n",
    "\n",
    "import numpy as np\n",
    "import datetime\n",
    "\n",
    "if past_flights_grouped.empty:\n",
    "\n",
    "    # Return the summary statistics.\n",
    "    summary_statistics = {\n",
    "        'status'          : 0,\n",
    "        'json_dict_30'    : {}\n",
    "    }\n",
    "else:\n",
    "    \n",
    "    # Filter the data for the next 1,7,15,30 days\n",
    "    current_date        = pd.to_datetime('today')\n",
    "    end_date_30         = current_date - datetime.timedelta(days=30)\n",
    "    past_30_days_data   = past_flights_grouped[(past_flights_grouped['flight_date'] <= current_date) & (past_flights_grouped['flight_date'] >= end_date_30)]\n",
    "\n",
    "    # Group by 'route', 'flight_no', 'flight_date' and get unique combinations\n",
    "    unique_combinations_30 = past_30_days_data[['route', 'flight_no', 'flight_date']].drop_duplicates()\n",
    "    \n",
    "    # Merge with another_df to get rows that match the grouped rows\n",
    "    result_df_30 = past_flights.merge(unique_combinations_30, on=['route', 'flight_no', 'flight_date'], how='inner').sort_values(by='generated_at', ascending=True)\n",
    "    \n",
    "    def identify_flights(group, deviation):\n",
    "        max_plf = group['plf'].cummax()  # Track the cumulative maximum PLF\n",
    "        has_reached_100 = group['plf'] >= 100\n",
    "        deviation_threshold = max_plf * deviation  # e.g. 10% deviation threshold\n",
    "        \n",
    "        # Check if PLF has dropped below 100 and the drop is more than 10% from the max PLF\n",
    "        has_significant_drop = (group['plf'] < 100) & (group['plf'] < deviation_threshold)\n",
    "        \n",
    "        # Check if the flight meets the criteria\n",
    "        if has_reached_100.any() and (has_significant_drop & has_reached_100.cummax()).any():\n",
    "            return True\n",
    "        return False\n",
    "    \n",
    "    # Apply the function to each group of flight_no and flight_date\n",
    "    result = result_df_30.groupby(['flight_no', 'flight_date']).filter(lambda group: identify_flights(group, deviation))\n",
    "    \n",
    "    unique_combinations_100_30 = result[['route', 'flight_no', 'flight_date']].drop_duplicates()\n",
    "    \n",
    "    result_df_100_30 = past_flights.merge(unique_combinations_100_30, on=['route', 'flight_no', 'flight_date'], how='inner').sort_values(by='generated_at', ascending=True)\n",
    "        \n",
    "    # Create a dictionary to store separate DataFrames\n",
    "    dataframes_dict_30 = {}\n",
    "    \n",
    "    # Iterate over unique combinations to create separate DataFrames\n",
    "    \n",
    "    for _, row in unique_combinations_100_30.iterrows():\n",
    "        route, flight_no, flight_date = row['route'], row['flight_no'], row['flight_date']\n",
    "        key = f\"{route}_{flight_no}_{flight_date}\"\n",
    "        dataframes_dict_30[key] = result_df_100_30[(result_df_100_30['route'] == route) &\n",
    "                                            (result_df_100_30['flight_no'] == flight_no) &\n",
    "                                            (result_df_100_30['flight_date'] == flight_date)]\n",
    "        \n",
    "    # Convert each DataFrame in the dictionary to JSON and store in a new dictionary\n",
    "    # json_dict_30 = {key: df.to_json(orient='records') for key, df in dataframes_dict_30.items()}\n",
    "    json_dict_30 = {key: df.to_json(orient='records') if not df.empty else None for key, df in dataframes_dict_30.items()}\n",
    "\n",
    "    # Return the summary statistics.\n",
    "    summary_statistics = {\n",
    "        'status'          : 1,\n",
    "        'json_dict_30'    : json_dict_30\n",
    "    }\n",
    "    \n",
    "# print(\"---------END: Analyzing Data---------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Dump"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "json_data       = json.dumps(summary_statistics)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
