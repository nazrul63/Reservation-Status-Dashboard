{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Introduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "goal: to analysis flight booking data form database to get the future booking status of next day, next 7, 15 and 30 day\n",
    "\n",
    "process flow:\n",
    "1. extract data from database\n",
    "2. transform data\n",
    "3. filter data\n",
    "4. process data\n",
    "5. send data as json to depict using charts\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pymysql\n",
    "\n",
    "# print(\"---------START: Reading Data---------\")\n",
    "mydb = pymysql.connect(\n",
    "    host = \"host_name\",\n",
    "    user = \"user_name\",\n",
    "    database = \"db_name\",\n",
    "    password = \"password\")\n",
    "\n",
    "column_header = ['route','flight_no','flight_date', 'total_seat','total_booked','plf','generated_at']\n",
    "\n",
    "mycursor = mydb.cursor()\n",
    "mycursor.execute('select route,flight_no,flight_date, total_seat, total_booked,plf,generated_at from table_name')\n",
    "\n",
    "df = pd.DataFrame(mycursor.fetchall())\n",
    "df.columns = column_header\n",
    "\n",
    "# print(\"---------END: Reading Data---------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"---------START: Transforming Data---------\")\n",
    "\n",
    "# Convert the columns to desired object.\n",
    "df['flight_date']   = pd.to_datetime(df['flight_date'])\n",
    "df['generated_at']  = pd.to_datetime(df['generated_at'])\n",
    "df['total_seat']    = df['total_seat'].astype(int)\n",
    "df['total_booked']  = df['total_booked'].astype(int)\n",
    "df['plf']           = df['plf'].astype(float).round(2)\n",
    "\n",
    "# print(\"---------END: Transforming Data---------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get today's date to fiter out future booking data\n",
    "today_date = pd.to_datetime('today')\n",
    "\n",
    "# Filter the data to only include flights with a flight date from today's date.\n",
    "future_flights  = df[df['flight_date'] >= today_date]\n",
    "future_flights_grouped = future_flights.loc[future_flights.groupby([ 'flight_no', 'flight_date','route'])['generated_at'].idxmax()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"---------START: Analyzing Data---------\")\n",
    "import datetime\n",
    "import numpy as np\n",
    "\n",
    "if future_flights_grouped.empty:\n",
    "\n",
    "    # Return the summary statistics.\n",
    "    summary_statistics = {\n",
    "        'status'                          : 0,\n",
    "        'total_bookings'                  : 0,\n",
    "        'total_capacity'                  : 0,\n",
    "        'average_booking_load_1'          : 0,\n",
    "        'average_booking_load_7'          : 0,\n",
    "        'average_booking_load_15'         : 0,\n",
    "        'average_booking_load_30'         : 0,\n",
    "        'date_0'                          : 0,\n",
    "        'date_1'                          : 0,\n",
    "        'date_7'                          : 0,\n",
    "        'date_15'                         : 0,\n",
    "        'date_30'                         : 0,\n",
    "        'last_update_date'                : 0,\n",
    "        'most_popular_specific_flight'    : 0,\n",
    "        'least_popular_specific_flight'   : 0,\n",
    "        'most_popular_overall_route_1'    : 0,\n",
    "        'least_popular_overall_route_1'   : 0,\n",
    "        'most_popular_overall_route_7'    : 0,\n",
    "        'least_popular_overall_route_7'   : 0,\n",
    "        'most_popular_overall_route_15'   : 0,\n",
    "        'least_popular_overall_route_15'  : 0,\n",
    "        'most_popular_overall_route_30'   : 0,\n",
    "        'least_popular_overall_route_30'  : 0,\n",
    "        'sorted_routes_1'                 : 0,\n",
    "        'sorted_routes_7'                 : 0,\n",
    "        'sorted_routes_15'                : 0,\n",
    "        'sorted_routes_30'                : 0,\n",
    "        'json_dict_1'                     : 0,\n",
    "        'json_dict_7'                     : 0,\n",
    "        'json_dict_15'                    : 0,\n",
    "        'json_dict_30'                    : 0\n",
    "        \n",
    "    }\n",
    "else:\n",
    "\n",
    "    # Calculate the total number of bookings.\n",
    "    total_bookings = future_flights_grouped['total_booked'].sum()\n",
    "    total_capacity = future_flights_grouped['total_seat'].sum()\n",
    "    \n",
    "    # Filter the data for the next 1,7,15,30 days\n",
    "    current_date = pd.to_datetime('today')\n",
    "    last_update_date = max(future_flights_grouped['generated_at'])\n",
    "    \n",
    "    end_date_tomorrow = current_date + datetime.timedelta(days=1)\n",
    "    next_1_days_data = future_flights_grouped[(future_flights_grouped['flight_date'] > current_date) & (future_flights_grouped['flight_date'] <= end_date_tomorrow)]\n",
    "\n",
    "    end_date_7 = current_date + datetime.timedelta(days=7)\n",
    "    next_7_days_data = future_flights_grouped[(future_flights_grouped['flight_date'] > current_date) & (future_flights_grouped['flight_date'] <= end_date_7)]\n",
    "\n",
    "    end_date_15 = current_date + datetime.timedelta(days=15)\n",
    "    next_15_days_data = future_flights_grouped[(future_flights_grouped['flight_date'] > current_date) & (future_flights_grouped['flight_date'] <= end_date_15)]\n",
    "\n",
    "    end_date_30 = current_date + datetime.timedelta(days=30)\n",
    "    next_30_days_data = future_flights_grouped[(future_flights_grouped['flight_date'] > current_date) & (future_flights_grouped['flight_date'] <= end_date_30)]\n",
    "\n",
    "    \n",
    "    plf_100_df_1  = next_1_days_data[next_1_days_data['plf'] >= 100]\n",
    "    plf_100_df_7  = next_7_days_data[next_7_days_data['plf'] >= 100]\n",
    "    plf_100_df_15 = next_15_days_data[next_15_days_data['plf'] >= 100]\n",
    "    plf_100_df_30 = next_30_days_data[next_30_days_data['plf'] >= 100]\n",
    "\n",
    "    # Group by 'route', 'flight_no', 'flight_date' and get unique combinations\n",
    "    unique_combinations_1  = plf_100_df_1[['route', 'flight_no', 'flight_date']].drop_duplicates()\n",
    "    unique_combinations_7  = plf_100_df_7[['route', 'flight_no', 'flight_date']].drop_duplicates()\n",
    "    unique_combinations_15 = plf_100_df_15[['route', 'flight_no', 'flight_date']].drop_duplicates()\n",
    "    unique_combinations_30 = plf_100_df_30[['route', 'flight_no', 'flight_date']].drop_duplicates()\n",
    "    \n",
    "    # Merge with another_df to get rows that match the grouped rows\n",
    "    result_df_1  = future_flights.merge(unique_combinations_1, on=['route', 'flight_no', 'flight_date'], how='inner').sort_values(by='generated_at', ascending=True)\n",
    "    result_df_7  = future_flights.merge(unique_combinations_7, on=['route', 'flight_no', 'flight_date'], how='inner').sort_values(by='generated_at', ascending=True)\n",
    "    result_df_15 = future_flights.merge(unique_combinations_15, on=['route', 'flight_no', 'flight_date'], how='inner').sort_values(by='generated_at', ascending=True)\n",
    "    result_df_30 = future_flights.merge(unique_combinations_30, on=['route', 'flight_no', 'flight_date'], how='inner').sort_values(by='generated_at', ascending=True)\n",
    "    \n",
    "    # Create a dictionary to store separate DataFrames\n",
    "    dataframes_dict_1  = {}\n",
    "    dataframes_dict_7  = {}\n",
    "    dataframes_dict_15 = {}\n",
    "    dataframes_dict_30 = {}\n",
    "    \n",
    "    # Iterate over unique combinations to create separate DataFrames\n",
    "    for _, row in unique_combinations_1.iterrows():\n",
    "        route, flight_no, flight_date = row['route'], row['flight_no'], row['flight_date']\n",
    "        key = f\"{route}_{flight_no}_{flight_date}\"\n",
    "        dataframes_dict_1[key] = result_df_1[(result_df_1['route'] == route) &\n",
    "                                            (result_df_1['flight_no'] == flight_no) &\n",
    "                                            (result_df_1['flight_date'] == flight_date)]\n",
    "        \n",
    "    # Convert each DataFrame in the dictionary to JSON and store in a new dictionary\n",
    "    json_dict_1 = {key: df.to_json(orient='records') for key, df in dataframes_dict_1.items()}\n",
    "    \n",
    "    for _, row in unique_combinations_7.iterrows():\n",
    "        route, flight_no, flight_date = row['route'], row['flight_no'], row['flight_date']\n",
    "        key = f\"{route}_{flight_no}_{flight_date}\"\n",
    "        dataframes_dict_7[key] = result_df_7[(result_df_7['route'] == route) &\n",
    "                                            (result_df_7['flight_no'] == flight_no) &\n",
    "                                            (result_df_7['flight_date'] == flight_date)]\n",
    "        \n",
    "    # Convert each DataFrame in the dictionary to JSON and store in a new dictionary\n",
    "    json_dict_7 = {key: df.to_json(orient='records') for key, df in dataframes_dict_7.items()}\n",
    "    \n",
    "    for _, row in unique_combinations_15.iterrows():\n",
    "        route, flight_no, flight_date = row['route'], row['flight_no'], row['flight_date']\n",
    "        key = f\"{route}_{flight_no}_{flight_date}\"\n",
    "        dataframes_dict_15[key] = result_df_15[(result_df_15['route'] == route) &\n",
    "                                            (result_df_15['flight_no'] == flight_no) &\n",
    "                                            (result_df_15['flight_date'] == flight_date)]\n",
    "        \n",
    "    # Convert each DataFrame in the dictionary to JSON and store in a new dictionary\n",
    "    json_dict_15 = {key: df.to_json(orient='records') for key, df in dataframes_dict_15.items()}\n",
    "    \n",
    "    for _, row in unique_combinations_30.iterrows():\n",
    "        route, flight_no, flight_date = row['route'], row['flight_no'], row['flight_date']\n",
    "        key = f\"{route}_{flight_no}_{flight_date}\"\n",
    "        dataframes_dict_30[key] = result_df_30[(result_df_30['route'] == route) &\n",
    "                                            (result_df_30['flight_no'] == flight_no) &\n",
    "                                            (result_df_30['flight_date'] == flight_date)]\n",
    "        \n",
    "    # Convert each DataFrame in the dictionary to JSON and store in a new dictionary\n",
    "    json_dict_30 = {key: df.to_json(orient='records') for key, df in dataframes_dict_30.items()}\n",
    "    \n",
    "    # Calculate the average booking load across all flights.\n",
    "    average_booking_load_1  = np.mean(next_1_days_data['plf']  )\n",
    "    average_booking_load_7  = np.mean(next_7_days_data['plf']  )\n",
    "    average_booking_load_15 = np.mean(next_15_days_data['plf'] )\n",
    "    average_booking_load_30 = np.mean(next_30_days_data['plf'] )\n",
    "    \n",
    "    df_sorted = future_flights_grouped.sort_values(by='plf', ascending=False)\n",
    "\n",
    "    # Get the best 3 and worst 3 specific flight numbers\n",
    "    best_3_specific = df_sorted.head(3)[['flight_no','flight_date','plf']]\n",
    "    worst_3_specific = df_sorted.tail(3)[['flight_no','flight_date','plf']]\n",
    "\n",
    "    # Group by 'route' and calculate the average load and total number of flights\n",
    "    route_summary_1 = next_1_days_data.groupby('route').agg(\n",
    "        average_load = ('plf', 'mean'),\n",
    "        total_flights = ('flight_date', 'count'),\n",
    "        total_flight_no = ('flight_no', 'count')\n",
    "    ).reset_index()\n",
    "    \n",
    "    # Sort the flights based on average load\n",
    "    sorted_routes_1 = route_summary_1.sort_values(by='average_load', ascending=False)\n",
    "\n",
    "    # Get the best 3 and worst 3 flight numbers\n",
    "    best_3_overall_route_1 = sorted_routes_1.head(3)\n",
    "    worst_3_overall_route_1 = sorted_routes_1.tail(3)[::-1]\n",
    "    \n",
    "    # Group by 'route' and calculate the average load and total number of flights\n",
    "    route_summary_7 = next_7_days_data.groupby('route').agg(\n",
    "        average_load = ('plf', 'mean'),\n",
    "        total_flights = ('flight_date', 'count'),\n",
    "        total_flight_no = ('flight_no', 'count')\n",
    "    ).reset_index()\n",
    "    \n",
    "    # Sort the flights based on average load\n",
    "    sorted_routes_7 = route_summary_7.sort_values(by='average_load', ascending=False)\n",
    "\n",
    "    # Get the best 3 and worst 3 flight numbers\n",
    "    best_3_overall_route_7 = sorted_routes_7.head(3)\n",
    "    worst_3_overall_route_7 = sorted_routes_7.tail(3)[::-1]\n",
    "    \n",
    "    # Group by 'route' and calculate the average load and total number of flights\n",
    "    route_summary_15 = next_15_days_data.groupby('route').agg(\n",
    "        average_load = ('plf', 'mean'),\n",
    "        total_flights = ('flight_date', 'count'),\n",
    "        total_flight_no = ('flight_no', 'count')\n",
    "    ).reset_index()\n",
    "    \n",
    "    # Sort the flights based on average load\n",
    "    sorted_routes_15 = route_summary_15.sort_values(by='average_load', ascending=False)\n",
    "\n",
    "    # Get the best 3 and worst 3 flight numbers\n",
    "    best_3_overall_route_15 = sorted_routes_15.head(3)\n",
    "    worst_3_overall_route_15 = sorted_routes_15.tail(3)[::-1]\n",
    "    \n",
    "    # Group by 'route' and calculate the average load and total number of flights\n",
    "    route_summary_30 = next_30_days_data.groupby('route').agg(\n",
    "        average_load = ('plf', 'mean'),\n",
    "        total_flights = ('flight_date', 'count'),\n",
    "        total_flight_no = ('flight_no', 'count')\n",
    "    ).reset_index()\n",
    "    \n",
    "    # Sort the flights based on average load\n",
    "    sorted_routes_30 = route_summary_30.sort_values(by='average_load', ascending=False)\n",
    "\n",
    "    # Get the best 3 and worst 3 flight numbers\n",
    "    best_3_overall_route_30 = sorted_routes_30.head(3)\n",
    "    worst_3_overall_route_30 = sorted_routes_30.tail(3)[::-1]\n",
    "\n",
    "    # Return the summary statistics.\n",
    "    summary_statistics = {\n",
    "        'status'                          : 1,\n",
    "        'total_bookings'                  : total_bookings.astype(str),\n",
    "        'total_capacity'                  : total_capacity.astype(str),\n",
    "        'average_booking_load_1'          : average_booking_load_1.astype(str),\n",
    "        'average_booking_load_7'          : average_booking_load_7.astype(str),\n",
    "        'average_booking_load_15'         : average_booking_load_15.astype(str),\n",
    "        'average_booking_load_30'         : average_booking_load_30.astype(str),\n",
    "        'date_0'                          : current_date.strftime('%d-%m-%Y'),\n",
    "        'date_1'                          : end_date_tomorrow.strftime('%d-%m-%Y'),\n",
    "        'date_7'                          : end_date_7.strftime('%d-%m-%Y'),\n",
    "        'date_15'                         : end_date_15.strftime('%d-%m-%Y'),\n",
    "        'date_30'                         : end_date_30.strftime('%d-%m-%Y'),\n",
    "        'last_update_date'                : last_update_date.strftime('%d-%m-%Y'),\n",
    "        'most_popular_specific_flight'    : best_3_specific.to_json(orient ='records'),\n",
    "        'least_popular_specific_flight'   : worst_3_specific.to_json(orient ='records'),\n",
    "        'most_popular_overall_route_1'    : best_3_overall_route_1.to_json(orient ='records'),\n",
    "        'least_popular_overall_route_1'   : worst_3_overall_route_1.to_json(orient ='records'),\n",
    "        'most_popular_overall_route_7'    : best_3_overall_route_7.to_json(orient ='records'),\n",
    "        'least_popular_overall_route_7'   : worst_3_overall_route_7.to_json(orient ='records'),\n",
    "        'most_popular_overall_route_15'   : best_3_overall_route_15.to_json(orient ='records'),\n",
    "        'least_popular_overall_route_15'  : worst_3_overall_route_15.to_json(orient ='records'),\n",
    "        'most_popular_overall_route_30'   : best_3_overall_route_30.to_json(orient ='records'),\n",
    "        'least_popular_overall_route_30'  : worst_3_overall_route_30.to_json(orient ='records'),\n",
    "        'sorted_routes_1'                 : sorted_routes_1.to_json(orient ='records'),\n",
    "        'sorted_routes_7'                 : sorted_routes_7.to_json(orient ='records'),\n",
    "        'sorted_routes_15'                : sorted_routes_15.to_json(orient ='records'),\n",
    "        'sorted_routes_30'                : sorted_routes_30.to_json(orient ='records'),\n",
    "        'json_dict_1'                     : json_dict_1,\n",
    "        'json_dict_7'                     : json_dict_7,\n",
    "        'json_dict_15'                    : json_dict_15,\n",
    "        'json_dict_30'                    : json_dict_30\n",
    "        \n",
    "    }\n",
    "    \n",
    "# print(\"---------END: Analyzing Data---------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Dump"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "json_data       = json.dumps(summary_statistics)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
