{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Introduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "goal: to insert data form txt file to database along with few new columns + new table to have the summary day wise\n",
    "\n",
    "process flow:\n",
    "1. read data from txt file\n",
    "2. extract desired data from read data\n",
    "3. clean data\n",
    "4. transform data\n",
    "5. filter data\n",
    "6. process data\n",
    "7. load data into database\n",
    "8. create a processed data file and relocate it\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Process Flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "dataFolder = r\"data_folder\"\n",
    "insertedFolder = r\"processed_data_folder\"\n",
    "\n",
    "for file in os.listdir(dataFolder):\n",
    "    if file.endswith('.TXT'):\n",
    "        file_path = dataFolder +\"\\\\\"+ file\n",
    "        # function to extract data from file\n",
    "        extracted_df = read_file(file_path)\n",
    "        \n",
    "        # function to clean data\n",
    "        cleaned_df = clean_file(extracted_df.copy())\n",
    "        \n",
    "        # function to get latitude and longitude of all airports\n",
    "        all_location =  get_all_geo_location()\n",
    "        \n",
    "        # function to transform data\n",
    "        transformed_df = transform_file(cleaned_df.copy(), all_location.copy())\n",
    "        \n",
    "        # function to filter data\n",
    "        grouped_df = group_data(transformed_df.copy())\n",
    "        \n",
    "        # function to process data to calculate PLF (pax load factor)\n",
    "        processed_df = get_PLF(grouped_df.copy())\n",
    "        \n",
    "        # fucntions to load data into database\n",
    "        loadedFile = insert_data_extraction_table(transformed_df.copy())\n",
    "        inserted_summary = insert_data_summary_table(processed_df.copy())\n",
    "        \n",
    "        # function to create processed data file and relocate it\n",
    "        relocate_file(file, file_path, insertedFolder, transformed_df.copy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extracting data from txt file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "generating_date = ''\n",
    "\n",
    "def read_file(file_path):\n",
    "    print(\"---------Reading & Filtering starting----------\")\n",
    "    \n",
    "    global generating_date\n",
    "    target_string = \"XX\"\n",
    "    generating_date_finder = \"End of Page\"\n",
    "    column_header = ['airline_code','route','flight_no','flight_date','flight_time','c_tot','j_bkd','w_bkd','y_bkd','tot_bkd']\n",
    "\n",
    "    df = pd.read_csv(file_path, header=None)\n",
    "    \n",
    "    matches = df[df.iloc[:, 0].astype(str).str.startswith(target_string)]\n",
    "    matches_target_date = df[df.iloc[:, 0].astype(str).str.startswith(generating_date_finder)]\n",
    "    generating_date = str(matches_target_date[0])[30:40]\n",
    "    \n",
    "    df1 = matches.iloc[:,0].str.split(expand=True)\n",
    "    df1.columns = column_header\n",
    "    \n",
    "    print(\"---------Reading & Filtering ending----------\")\n",
    "    \n",
    "    return df1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cleaning data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def clean_file(filtered_df):\n",
    "    print(\"---------Cleaning starting----------\")\n",
    "    \n",
    "    # clearing custom flights like CRCHDQ\n",
    "    for i in range(len(filtered_df)):        \n",
    "        if len(filtered_df.iloc[i,1]) > 6:\n",
    "            tobesplited = filtered_df.iloc[i,1]\n",
    "            filtered_df.iloc[i,1], filtered_df.iloc[i,2:], filtered_df.iloc[i,2] = tobesplited[:6], filtered_df.iloc[i,2:].shift(1), tobesplited[6:]\n",
    "    \n",
    "    # changing data types\n",
    "    d3= filtered_df.convert_dtypes()\n",
    "    d3.replace('', np.nan, inplace=True)\n",
    "\n",
    "    # Identify the columns intended to be integers\n",
    "    int_columns = ['flight_no', 'c_tot', 'j_bkd', 'w_bkd', 'y_bkd', 'tot_bkd']\n",
    "    \n",
    "    # Convert columns to integers and handle NaN or infinite values\n",
    "    d3[int_columns] = d3[int_columns].apply(lambda x: pd.to_numeric(x, errors='coerce')).astype('Int64')\n",
    "    \n",
    "    d3['flight_timestamp'] = pd.to_datetime(d3['flight_date'] + ' ' + d3['flight_time'])\n",
    "    d3['flight_date'] = d3['flight_date'].apply(lambda x: transform_date(x))\n",
    "\n",
    "    df_datatype_corrected = d3\n",
    "    non_numeric_columns = df_datatype_corrected.select_dtypes(exclude=['number', 'datetime']).columns\n",
    "    df_datatype_corrected[non_numeric_columns] = df_datatype_corrected[non_numeric_columns].fillna('N/A')\n",
    "    \n",
    "    df_nullCellTransformed = df_datatype_corrected.fillna(0)\n",
    "    df_allCellTrimmed = trim_all_columns(df_nullCellTransformed)\n",
    "    \n",
    "    print(\"---------Cleaning ending----------\")\n",
    "    return df_allCellTrimmed\n",
    "\n",
    "def trim_all_columns(df):\n",
    "    \"\"\"\n",
    "    Trim whitespace from ends of each value across all series in dataframe\n",
    "    \"\"\"\n",
    "    trim_strings = lambda x: x.strip() if isinstance(x, str) else x\n",
    "    return df.applymap(trim_strings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting all Station's Geo-Location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymysql\n",
    "\n",
    "def get_all_geo_location():\n",
    "    print(\"---------START: Reading All_Geo_Location Data---------\")\n",
    "\n",
    "    global df_geo_location\n",
    "    \n",
    "    mydb_connection = pymysql.connect(\n",
    "        host = \"host_name\",\n",
    "        user = \"user_name\",\n",
    "        database = \"db_name\",\n",
    "        password = \"password\")\n",
    "    \n",
    "    mycursor = mydb_connection.cursor()\n",
    "    \n",
    "    # Execute the first query to retrieve all latitude and longitude from tha database\n",
    "    origin_query = \"SELECT iata_code, latitude, longitude FROM table_name\"\n",
    "    mycursor.execute(origin_query)    \n",
    "    df_geo_location = pd.DataFrame(mycursor.fetchall())\n",
    "    \n",
    "    # Close the cursor and the connection\n",
    "    mycursor.close()\n",
    "    mydb_connection.close()\n",
    "    \n",
    "    column_header = ['iata_code','latitude','longitude']\n",
    "    df_geo_location.columns = column_header\n",
    "    \n",
    "    df_geo_location = df_geo_location[df_geo_location['iata_code'] != r'\\N']\n",
    "    \n",
    "    df_geo_location['latitude'] = df_geo_location['latitude'].astype(float)\n",
    "    df_geo_location['longitude'] = df_geo_location['longitude'].astype(float)\n",
    "    \n",
    "    print(\"---------END: Reading All_Geo_location Data---------\")\n",
    "    return df_geo_location"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "def transform_file(cleaned_df, all_location):\n",
    "    print(\"---------Transforming starting for----------\")\n",
    "    global df_merged\n",
    "    \n",
    "    cleaned_df['origin']        = cleaned_df['route'].apply(lambda x: x[:3])\n",
    "    cleaned_df['destination']   = cleaned_df['route'].apply(lambda x : x[3:])\n",
    "    cleaned_df['day_of_week']   = cleaned_df['flight_date'].apply(lambda x: get_day(x))\n",
    "    cleaned_df['generated_at']  = transform_date(generating_date)\n",
    "   \n",
    "    # assume that df is the large dataset and db is the table in the database\n",
    "    df_merged = pd.merge(cleaned_df, all_location, left_on='origin', right_on='iata_code', how='left')\n",
    "    df_merged = pd.merge(df_merged, all_location, left_on='destination', right_on='iata_code', how='left', suffixes=('_origin', '_destination'))\n",
    "\n",
    "    # assume that df is the dataframe with columns latitude_origin, longitude_origin, latitude_destination, longitude_destination\n",
    "    df_merged['distance_km'] = calculate_distance_vec(df_merged['latitude_origin'], df_merged['longitude_origin'], df_merged['latitude_destination'], df_merged['longitude_destination'])\n",
    "    \n",
    "    df_merged['distance_km'] = pd.to_numeric(df_merged['distance_km'], errors='coerce')\n",
    "    df_merged['rpk'] = df_merged['tot_bkd'] * df_merged['distance_km']\n",
    "    \n",
    "    # Columns to exclude\n",
    "    columns_to_exclude = ['iata_code_origin', 'latitude_origin', 'longitude_origin', 'iata_code_destination', 'latitude_destination', 'longitude_destination']\n",
    "    \n",
    "    # Using drop() method\n",
    "    df_merged_copy_1 = df_merged.drop(columns=columns_to_exclude, inplace=False)\n",
    "\n",
    "    print(\"---------Transforming ending----------\")\n",
    "    return df_merged_copy_1\n",
    "\n",
    "def transform_date(input_date):\n",
    "    formats = ['%m/%d/%Y', '%m/%d/%y', '%d/%m/%Y', '%d/%m/%y', \"%b'%y\"]\n",
    "    for date_format in formats:\n",
    "        try:\n",
    "            date_obj = datetime.strptime(input_date, date_format)\n",
    "            return date_obj.strftime('%Y-%m-%d')\n",
    "        except ValueError:\n",
    "            continue\n",
    "    raise ValueError('Invalid date format: {}'.format(input_date))\n",
    "\n",
    "def get_day(input_date):\n",
    "    formats = ['%m/%d/%Y', '%m/%d/%y', '%d/%m/%Y', '%d/%m/%y', \"%b'%y\", '%Y-%m-%d']\n",
    "    for date_format in formats:\n",
    "        try:\n",
    "            date_obj = datetime.strptime(input_date, date_format)\n",
    "            day_of_week = date_obj.weekday()\n",
    "            return day_of_week\n",
    "        except ValueError:\n",
    "            continue\n",
    "    raise ValueError('Invalid date format: {}'.format(input_date))\n",
    "\n",
    "def calculate_distance_vec(lat1, lon1, lat2, lon2):\n",
    "    \n",
    "    radius_earth = 6.371E3  # km\n",
    "    phi1         = np.radians(lat1)\n",
    "    phi2         = np.radians(lat2)\n",
    "    delta_phi    = np.radians(lat1 - lat2)\n",
    "    delta_lam    = np.radians(lon1 - lon2)\n",
    "\n",
    "    a = np.sin(0.5 * delta_phi)**2 + np.cos(phi1) * np.cos(phi2) * np.sin(0.5 * delta_lam)**2\n",
    "    c = 2 * np.arctan2(np.sqrt(a), np.sqrt(1 - a))\n",
    "\n",
    "    distance_km = radius_earth * c\n",
    "    return distance_km"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_data(df):\n",
    "    # print(\"---------START: Grouping Data---------\")\n",
    "    \n",
    "    # today_date = pd.to_datetime('today')\n",
    "    exclude_list = ['CRCHDQ', 'AAABBB']\n",
    "    df.drop(df[df['route'].isin(exclude_list)].index, inplace = True) \n",
    "    \n",
    "    future_flights_grouped = df.sort_values(by=['flight_no', 'flight_timestamp', 'route', 'generated_at'])\n",
    "    \n",
    "    temp_storage = {'origin1': '', 'destination1': '', 'flight_no': '','origin2': '', 'destination2': '', 'flight_date': '', 'journey_date': '', 'flight_timestamp': ''}\n",
    "\n",
    "    results = future_flights_grouped.apply(lambda row: accumulate_segment(row, temp_storage), axis=1)\n",
    "    future_flights_grouped['journey_date'] = results.apply(lambda x: x[0])\n",
    "    \n",
    "    # print(\"---------END: Grouping Data---------\")\n",
    "    return future_flights_grouped\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below algorithm finds out the segments of a flight based on flight_no, flight_date, flight_time, origin and destination. For example, if the flight having flight_no 111 of flight_date 2222-02-22 have segments like AAA-BBB, AAA-CCC and BBB-CCC within one day interval, then below function will consider them as segment i.e. part of same flight and will state the flight route as AAA-BBB-CCC.\n",
    "\n",
    "![alt text](<Copy of algo_segment_accumulator.drawio.png>)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def accumulate_segment(row, temp_storage):\n",
    "    flight_no        = row['flight_no']\n",
    "    flight_date      = row['flight_date']\n",
    "    flight_timestamp = row['flight_timestamp']\n",
    "    origin           = row['origin']\n",
    "    destination      = row['destination']\n",
    "    \n",
    "    # if current and previous flight no are same\n",
    "    if flight_no == temp_storage['flight_no']:\n",
    "        # if current and previous flight date are same\n",
    "        if flight_date == temp_storage['flight_date']:\n",
    "            # if current and previous flight_no flight_date are same and already have 3rd segment\n",
    "            if temp_storage['origin2'] and temp_storage['destination2']:\n",
    "                temp_storage['journey_date'] = flight_date\n",
    "                temp_storage['flight_no'] = flight_no\n",
    "                temp_storage['flight_date'] = flight_date\n",
    "                temp_storage['origin1'] = ''\n",
    "                temp_storage['destination1'] = ''\n",
    "                temp_storage['origin2'] = ''\n",
    "                temp_storage['destination2'] = ''\n",
    "                temp_storage['flight_timestamp'] = flight_timestamp\n",
    "            # if current and previous flight_no flight_date are same and already have doesn't have 3rd segment\n",
    "            else:\n",
    "                temp_storage['journey_date'] = flight_date\n",
    "                temp_storage['origin2'] = origin\n",
    "                temp_storage['destination2'] = destination\n",
    "                temp_storage['flight_no'] = flight_no\n",
    "                temp_storage['flight_date'] = flight_date\n",
    "                temp_storage['flight_timestamp'] = flight_timestamp\n",
    "        # if current and previous flight_no are same but flight_date are NOT same\n",
    "        else:\n",
    "            # if current and previous flight_no are same and flight_date are NOT same but flight_dates have difference of one day\n",
    "            if ((pd.to_datetime(flight_date) - pd.to_datetime(temp_storage['journey_date'])) == pd.Timedelta(days=1)):\n",
    "                # if it has one segment\n",
    "                if temp_storage['origin1'] and temp_storage['destination1']:\n",
    "                    # if it has 2nd segment\n",
    "                    if temp_storage['origin2'] and temp_storage['destination2']:\n",
    "                        if ((origin == temp_storage['destination1'] and destination == temp_storage['destination2']) or (destination == temp_storage['destination1'] and origin == temp_storage['destination2'])):\n",
    "                            temp_storage['flight_no'] = flight_no\n",
    "                            temp_storage['flight_date'] = flight_date\n",
    "                            temp_storage['origin1'] = origin\n",
    "                            temp_storage['destination1'] = destination\n",
    "                            temp_storage['origin2'] = ''\n",
    "                            temp_storage['destination2'] = ''\n",
    "                            temp_storage['flight_timestamp'] = flight_timestamp\n",
    "                        else:\n",
    "                            temp_storage['journey_date'] = flight_date\n",
    "                            temp_storage['flight_no'] = flight_no\n",
    "                            temp_storage['flight_date'] = flight_date\n",
    "                            temp_storage['origin1'] = origin\n",
    "                            temp_storage['destination1'] = destination\n",
    "                            temp_storage['origin2'] = ''\n",
    "                            temp_storage['destination2'] = ''\n",
    "                            temp_storage['flight_timestamp'] = flight_timestamp\n",
    "                    else:\n",
    "                        # if the flight is of same number and route but of next day's; so new flight \n",
    "                        if origin == temp_storage['origin1'] and destination == temp_storage['destination1']:\n",
    "                            temp_storage['journey_date'] = flight_date\n",
    "                            temp_storage['origin1'] = origin\n",
    "                            temp_storage['destination1'] = destination\n",
    "                            temp_storage['origin2'] = ''\n",
    "                            temp_storage['destination2'] = ''\n",
    "                            temp_storage['flight_no'] = flight_no\n",
    "                            temp_storage['flight_date'] = flight_date\n",
    "                            temp_storage['flight_timestamp'] = flight_timestamp\n",
    "                        # if the flights are of same number and origin but of next day's; \n",
    "                        elif origin == temp_storage['origin1'] and destination != temp_storage['destination1']: \n",
    "                            if flight_timestamp != temp_storage['flight_timestamp']:\n",
    "                                temp_storage['journey_date'] = flight_date\n",
    "                                temp_storage['origin1'] = origin\n",
    "                                temp_storage['destination1'] = destination\n",
    "                                temp_storage['origin2'] = ''\n",
    "                                temp_storage['destination2'] = ''\n",
    "                                temp_storage['flight_no'] = flight_no\n",
    "                                temp_storage['flight_date'] = flight_date\n",
    "                                temp_storage['flight_timestamp'] = flight_timestamp\n",
    "                            else:\n",
    "                                temp_storage['journey_date'] = temp_storage['journey_date']\n",
    "                                temp_storage['flight_no'] = flight_no\n",
    "                                temp_storage['flight_date'] = temp_storage['flight_date']\n",
    "                                temp_storage['origin2'] = origin\n",
    "                                temp_storage['destination2'] = destination\n",
    "                                temp_storage['flight_timestamp'] = flight_timestamp\n",
    "                        elif origin == temp_storage['destination1'] and destination != temp_storage['origin1']: \n",
    "                            temp_storage['journey_date'] = temp_storage['journey_date']\n",
    "                            temp_storage['flight_no'] = flight_no\n",
    "                            temp_storage['flight_date'] = temp_storage['flight_date']\n",
    "                            temp_storage['origin2'] = origin\n",
    "                            temp_storage['destination2'] = destination\n",
    "                            temp_storage['flight_timestamp'] = flight_timestamp\n",
    "                        elif destination == temp_storage['destination1'] and origin != temp_storage['origin1']: \n",
    "                            temp_storage['journey_date'] = temp_storage['journey_date']\n",
    "                            temp_storage['flight_no'] = flight_no\n",
    "                            temp_storage['flight_date'] = temp_storage['flight_date']\n",
    "                            temp_storage['origin2'] = origin\n",
    "                            temp_storage['destination2'] = destination\n",
    "                            temp_storage['flight_timestamp'] = flight_timestamp\n",
    "                # if the flight has no segment enlisted\n",
    "                else:\n",
    "                    temp_storage['journey_date'] = flight_date\n",
    "                    temp_storage['origin1'] = origin\n",
    "                    temp_storage['destination1'] = destination\n",
    "                    temp_storage['origin2'] = ''\n",
    "                    temp_storage['destination2'] = ''\n",
    "                    temp_storage['flight_no'] = flight_no\n",
    "                    temp_storage['flight_date'] = flight_date\n",
    "                    temp_storage['flight_timestamp'] = flight_timestamp\n",
    "                    \n",
    "            \n",
    "            # if current and previous flight_no are same and flight_date are NOT same and flight_dates have difference greater than one day\n",
    "            else:\n",
    "                temp_storage['journey_date'] = flight_date\n",
    "                temp_storage['origin1'] = origin\n",
    "                temp_storage['destination1'] = destination\n",
    "                temp_storage['origin2'] = ''\n",
    "                temp_storage['destination2'] = ''\n",
    "                temp_storage['flight_no'] = flight_no\n",
    "                temp_storage['flight_date'] = flight_date\n",
    "                temp_storage['flight_timestamp'] = flight_timestamp\n",
    "                \n",
    "    # if current and previous flight no are NOT same\n",
    "    else:\n",
    "        temp_storage['origin1'] = origin\n",
    "        temp_storage['destination1'] = destination\n",
    "        temp_storage['origin2'] = ''\n",
    "        temp_storage['destination2'] = ''\n",
    "        temp_storage['flight_no'] = flight_no\n",
    "        temp_storage['flight_date'] = flight_date\n",
    "        temp_storage['journey_date'] = flight_date\n",
    "        temp_storage['flight_timestamp'] = flight_timestamp\n",
    "    \n",
    "    return (temp_storage['journey_date'], temp_storage['flight_no'],temp_storage['flight_date'], temp_storage['flight_timestamp'])\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculating PLF (Pax Load Factor) by determining ASK and RPK of the airports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_PLF(future_flights_grouped):\n",
    "\n",
    "    # print(\"---------START: Filtering Data---------\")\n",
    "    def calculate_ask_distance(row, temp_storage):\n",
    "        origin      = row['origin']\n",
    "        destination = row['destination']\n",
    "        distance    = row['distance_km']\n",
    "    \n",
    "        if temp_storage['origin1'] and temp_storage['destination1']:\n",
    "            if temp_storage['origin2'] and temp_storage['destination2']:\n",
    "                if origin == temp_storage['destination1']:\n",
    "                    temp_storage['total_distance'] = distance + temp_storage['distance1']\n",
    "                    temp_storage['route'] = temp_storage['origin1'] + '-' + temp_storage['destination1'] + '-' + destination\n",
    "                elif origin == temp_storage['destination2']:\n",
    "                    temp_storage['total_distance'] = distance + temp_storage['distance2']\n",
    "                    temp_storage['route'] = temp_storage['origin2'] + '-' + temp_storage['destination2'] + '-' + destination\n",
    "                elif origin == temp_storage['origin1'] and destination == temp_storage['origin2']:\n",
    "                    temp_storage['total_distance'] += distance \n",
    "                    temp_storage['route'] = temp_storage['origin1'] + '-' + temp_storage['origin2'] + '-' + temp_storage['destination2']\n",
    "                elif origin == temp_storage['origin2'] and destination == temp_storage['origin1']:\n",
    "                    temp_storage['total_distance'] += distance \n",
    "                    temp_storage['route'] = temp_storage['origin2'] + '-' + temp_storage['origin1'] + '-' + temp_storage['destination1']\n",
    "                    \n",
    "            else:\n",
    "                if origin == temp_storage['origin1'] or destination == temp_storage['destination1']:\n",
    "                    temp_storage['origin2'] = origin\n",
    "                    temp_storage['destination2'] = destination\n",
    "                    temp_storage['distance2'] = distance  \n",
    "                elif origin == temp_storage['destination1']:\n",
    "                    temp_storage['origin2'] = origin\n",
    "                    temp_storage['destination2'] = destination\n",
    "                    temp_storage['distance2'] = distance\n",
    "                    temp_storage['total_distance'] += distance\n",
    "                    temp_storage['route'] = temp_storage['origin1'] + '-' + temp_storage['destination1'] + '-' + destination\n",
    "                    # print(\"this route is transit point\")\n",
    "                elif destination == temp_storage['origin1']:\n",
    "                    temp_storage['origin2'] = origin\n",
    "                    temp_storage['destination2'] = destination\n",
    "                    temp_storage['distance2'] = distance\n",
    "                    temp_storage['total_distance'] += distance\n",
    "                    temp_storage['route'] = origin +  '-' + destination + '-' + temp_storage['destination1'] \n",
    "                    # print(\"this route is transit point\")\n",
    "        else:\n",
    "            temp_storage['origin1'] = origin\n",
    "            temp_storage['destination1'] = destination\n",
    "            temp_storage['distance1'] = distance\n",
    "            temp_storage['total_distance'] = distance\n",
    "            temp_storage['route'] = origin +  '-' + destination\n",
    "            # print(row['flight_no'], row['flight_date'] ,origin, destination)\n",
    "            \n",
    "        # print(origin,destination,distance,temp_storage['total_distance'])\n",
    "    \n",
    "    \n",
    "        return (temp_storage['total_distance'],temp_storage['route'])\n",
    "\n",
    "    # Define a custom aggregation function to multiply 'total' by 'a' and retain other columns\n",
    "    def calculate_plf(group):\n",
    "        temp_storage = {'origin1': '', 'destination1': '', 'distance1': 0,'origin2': '', 'destination2': '', 'distance2': 0, 'total_distance': 0, 'route': ''}\n",
    "    \n",
    "        results = group.apply(lambda row: calculate_ask_distance(row, temp_storage), axis=1)\n",
    "        group['total_distance'] = results.apply(lambda x: x[0])\n",
    "        group['route'] = results.apply(lambda x: x[1])\n",
    "    \n",
    "        flight_no = group['flight_no'].iloc[0]\n",
    "        journey_date = group['journey_date'].iloc[0]\n",
    "        generated_at = group['generated_at'].iloc[0]\n",
    "        total_RPK = group['rpk'].sum()\n",
    "        total_booked = group['tot_bkd'].sum()\n",
    "        total_seat = group['c_tot'].iloc[0]\n",
    "        \n",
    "        total_distance = group['total_distance'].iloc[-1]  # Get the last accumulated distance\n",
    "        total_route = group['route'].iloc[-1]  # Get the last route\n",
    "        plf = (total_RPK / (total_seat * total_distance)) * 100 if total_seat * total_distance != 0 else 0\n",
    "    \n",
    "        return pd.Series({\n",
    "            'flight_no': flight_no, \n",
    "            'route': total_route,\n",
    "            'flight_date': journey_date,\n",
    "            'total_seat': total_seat, \n",
    "            'total_booked': total_booked, \n",
    "            'total_distance': total_distance,\n",
    "            'total_RPK': total_RPK, \n",
    "            'total_ASK': total_seat * total_distance, \n",
    "            'plf': plf,\n",
    "            'generated_at': generated_at\n",
    "        })\n",
    "    \n",
    "    # Group by 'flight_no', 'flight_date', 'route' and aggregate using the custom function\n",
    "    future_flights_grouped = future_flights_grouped.groupby(['flight_no', 'journey_date']).apply(calculate_plf)\n",
    "\n",
    "    # Reset index to convert the resulting series to a DataFrame\n",
    "    future_flights_grouped = future_flights_grouped.reset_index(drop=True)\n",
    "\n",
    "    # print(\"---------END: Filtering Data---------\")\n",
    "    return future_flights_grouped"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine\n",
    "import pymysql\n",
    "\n",
    "def insert_data_extraction_table(transformed_df):\n",
    "    print(\"---------Loading starting----------\")    \n",
    "    df_data_reset = transformed_df.reset_index(drop=True)\n",
    "    \n",
    "    mydb = pymysql.connect(\n",
    "            host     = \"host_name\",\n",
    "            user     = \"user_name\",\n",
    "            database = \"db_name\",\n",
    "            password = \"password\")\n",
    "\n",
    "    engine = create_engine(\"mysql+pymysql://{user}:{pw}@{host}/{db}\"\n",
    "                           .format(user = \"user_name\",\n",
    "                                   host = \"host_name\",\n",
    "                                   pw   = \"password\",\n",
    "                                   db   = \"db_name\"))\n",
    "    \n",
    "    SQL_CREATE_TBL = \"CREATE TABLE IF NOT EXISTS table_name(id INT NOT NULL AUTO_INCREMENT,\"\n",
    "    for name in range(0, len(df_data_reset.columns)):\n",
    "        SQL_CREATE_TBL += \"{} TEXT, \".format(df_data_reset.columns[name])\n",
    "    \n",
    "    # SQL_CREATE_TBL = SQL_CREATE_TBL.rstrip(\" ,\")\n",
    "    SQL_CREATE_TBL += \"created_at timestamp NOT NULL DEFAULT current_timestamp(), updated_at timestamp NOT NULL DEFAULT current_timestamp(), PRIMARY KEY (id));\"\n",
    "    \n",
    "    mycursor = mydb.cursor()\n",
    "    \n",
    "    try:\n",
    "        print(\"Creating table {}: \".format(\"table_name\"), end='')\n",
    "        mycursor.execute(SQL_CREATE_TBL)\n",
    "        sql_formated = df_data_reset.to_sql('table_name', con= engine, if_exists= 'append', chunksize=1000, index=False)\n",
    "    except pymysql.Error as err:\n",
    "        # if err.errno == ER_TABLE_EXISTS_ERROR:\n",
    "        #     print(\"already exists.\")\n",
    "        # else:\n",
    "        print(err)\n",
    "    else:\n",
    "        print(\"OK\")\n",
    "        \n",
    "    print(\"---------Loading ended----------\")\n",
    "    \n",
    "def insert_data_summary_table (df_data_final):\n",
    "    \n",
    "    # print(\"---------Loading starting for----------\")\n",
    "    \n",
    "    mydb = pymysql.connect(\n",
    "        host = \"host_name\",\n",
    "        user = \"user_name\",\n",
    "        database = \"db_name\",\n",
    "        password = \"password\")\n",
    "\n",
    "    engine = create_engine(\"mysql+pymysql://{user}:{pw}@{host}/{db}\"\n",
    "                           .format(user=\"user_name\",\n",
    "                                   host=\"host_name\",\n",
    "                                   pw=\"password\",\n",
    "                                   db=\"db_name\"))\n",
    "    df_data_reset = df_data_final.reset_index(drop=True)\n",
    "    \n",
    "    # Define a mapping from Pandas data types to SQL data types and default values\n",
    "\n",
    "    pandas_to_sql_type_mapping = {\n",
    "        'int32': {'type': 'INT', 'default': '0'},\n",
    "        'int64': {'type': 'INT', 'default': '0'},\n",
    "        'float64': {'type': 'FLOAT', 'default': '0.0'},\n",
    "        'object': {'type': 'TEXT', 'default': \"''\"},  # Default empty string for text\n",
    "        'datetime64[ns]': {'type': 'TIMESTAMP', 'default': 'CURRENT_TIMESTAMP'},  # Example of using a function as a default\n",
    "    }\n",
    "\n",
    "    \n",
    "    SQL_CREATE_TBL = \"CREATE TABLE IF NOT EXISTS table_name(id INT NOT NULL AUTO_INCREMENT,\"\n",
    "    \n",
    "    for column_name, data_type in zip(df_data_reset.columns, df_data_reset.dtypes):\n",
    "        # Retrieve the mapping for the current data type\n",
    "        sql_type_info = pandas_to_sql_type_mapping.get(str(data_type), {'type': 'TEXT', 'default': \"''\"})\n",
    "        sql_data_type = sql_type_info['type']\n",
    "        default_value = sql_type_info['default']\n",
    "    \n",
    "        # Add column definition to the SQL statement with default values\n",
    "        SQL_CREATE_TBL += \"{} {} DEFAULT {}, \".format(column_name, sql_data_type, default_value)\n",
    "\n",
    "    SQL_CREATE_TBL += \"created_at TIMESTAMP NOT NULL DEFAULT current_timestamp(), updated_at TIMESTAMP NOT NULL DEFAULT current_timestamp(), PRIMARY KEY (id));\"\n",
    "    \n",
    "    mycursor = mydb.cursor()\n",
    "    \n",
    "    def insert_ignore(table, conn, keys, data_iter):\n",
    "        from sqlalchemy.ext.compiler import compiles\n",
    "        from sqlalchemy.sql.expression import Insert\n",
    "    \n",
    "        @compiles(Insert)\n",
    "        def replace_string(insert, compiler, **kw):\n",
    "            s = compiler.visit_insert(insert, **kw)\n",
    "            s = s.replace(\"INSERT INTO\", \"INSERT IGNORE INTO\")\n",
    "            return s\n",
    "    \n",
    "        data = [dict(zip(keys, row)) for row in data_iter]\n",
    "        conn.execute(table.table.insert(), data)\n",
    "\n",
    "    try:\n",
    "        # print(\"Creating table {}: \".format(\"flight_status\"), end='')\n",
    "        mycursor.execute(SQL_CREATE_TBL)\n",
    "        # df_data_reset.to_sql('table_name', con= engine, if_exists= 'append', chunksize=1000, index=False)\n",
    "        df_data_reset.to_sql('table_name', con=engine, if_exists='append', index=False, method=insert_ignore)\n",
    "    except pymysql.Error as err:\n",
    "        # print(err)\n",
    "        pass\n",
    "    # else:\n",
    "        # print(\"OK\")\n",
    "        \n",
    "    print(\"---------Loading ended ----------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating processed data file and relocating it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import pathlib\n",
    "\n",
    "def relocate_file(file, file_path, insertedFolder, transformedFile):\n",
    "    print(\"---------Renaming and Relocating starting----------\")\n",
    "    \n",
    "    timestr = time.strftime(\"%Y%m%d_%H%M%S_\")\n",
    "    transformedDataFile =  timestr + transformedFile.iloc[0].generated_at + \"_\"+transformedFile['flight_date'].iloc[0]+\"_\"+transformedFile['flight_date'].iloc[-1]+\".xlsx\"\n",
    "    uploaded_file_path = insertedFolder + \"\\\\\" + transformedDataFile\n",
    "    transformedFile.to_excel(uploaded_file_path, index= False)\n",
    "    \n",
    "    backup_file_path = insertedFolder + \"\\\\\" + timestr + file\n",
    "    newName = pathlib.PurePosixPath(backup_file_path).stem + '.TXT'\n",
    "    \n",
    "    os.rename(file_path, newName)\n",
    "    \n",
    "    print(\"---------Renaming and Relocating ended----------\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
